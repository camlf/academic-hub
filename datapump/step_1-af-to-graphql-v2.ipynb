{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset-to-Hub pipeline: reduce Time-to-Publish in onboarding datasets \n",
    "\n",
    "Goal: from a PI System with associated AF database, publish the dataset through OCS with a set of default asset-centric Data Views. \n",
    "\n",
    "#### Showcase datasets: Deschutes and UC Davis Facilities. Next: NC State paper machines, USC drill data\n",
    "\n",
    "## Step 1: Populate GraphQL-enabled \"AF\" \n",
    "\n",
    "#### From an AF path element, collect pipoints/static/etc about all its children elements. \n",
    "\n",
    "#### This data is then directly accessible through a GraphQL endpoint for Step 1, creation of (graph) data views. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import to deal with PIWebAPI\n",
    "# !pip install httpx\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from time import process_time\n",
    "import yaml\n",
    "import asyncio\n",
    "import httpx\n",
    "\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import urllib3\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# from py2neo import Graph\n",
    "\n",
    "# Graph module\n",
    "import py2neo\n",
    "from py2neo import Node, Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# config_file = \"config-omf-health.yaml\"\n",
    "# config_file = \"config-prod-ucd-v2.yaml\"\n",
    "config_file = \"config-windfarm.yaml\"\n",
    "# config_file = \"config-acad-prod-desc-v2.yaml\"\n",
    "# config_file = \"config-acad-prod-deschutes.yaml\"\n",
    "#  config_file = \"config-acad-prod-ucd.yaml\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "From an anchor element path in AF, populate a GraphQL-enabled \"mirror\" of its children elements and their attributes, extracted from PIWebAPI \n",
    "\n",
    "### Input parameters\n",
    "\n",
    "* PIWebAPI base URL for asset servers\n",
    "* PIWebAPI authentication credentials (basic)\n",
    "* Anchor element path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = config[\"piwebapi\"][\"base_url\"]\n",
    "dataserver = config[\"piwebapi\"][\"dataserver\"]  # \"uni-pida-vm0\"\n",
    "\n",
    "auth = (config[\"piwebapi\"][\"username\"], config[\"piwebapi\"][\"password\"])\n",
    "timeout = 45.0\n",
    "\n",
    "asset_url = base_url + \"/assetservers\"\n",
    "\n",
    "print(f\"piwebapi={base_url}, dataserver={dataserver}, auth=(*****, *****)\")\n",
    "\n",
    "element_roots = config[\"piwebapi\"][\"element_roots\"]\n",
    "\n",
    "test_asset = None\n",
    "\n",
    "ocs_asset_db = config[\"ocs\"][\"configuration\"][\"asset_db\"]\n",
    "\n",
    "EXPAND_LEAF_ELEMENTS = config[\"piwebapi\"][\"expand_leaf_elements\"]  # False\n",
    "MAX_LEAF_ELEMENTS = 10000\n",
    "print(f\"roots = {element_roots}, expand leaves: {EXPAND_LEAF_ELEMENTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to navigate PIWebAPI structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_webid(webid):\n",
    "    return f\"{ocs_asset_db}:{webid}\"\n",
    "\n",
    "\n",
    "# From PIWebAPI asset node, build directory of children links and self WebID\n",
    "# If extract_key is present, return this directory item\n",
    "# Otherwise return full dictionary (key is children node name)\n",
    "async def extract_url(url, key, extract_key=None, debug=False):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        start = process_time()\n",
    "        print(\"<\", end=\"\")\n",
    "        r = await client.get(url, auth=auth, timeout=timeout)\n",
    "        # print(f\"[{process_time() - start:.2f}:{url}]\")\n",
    "        if r.status_code != 200:\n",
    "            print(f\"@error  code={r.status_code}, url={url}\")\n",
    "            return\n",
    "        js = r.json()\n",
    "        if debug:\n",
    "            print(f\"js={js}\")\n",
    "        d = {\n",
    "            i[\"Name\"]: (\n",
    "                i[\"Links\"][f\"{key}\"],\n",
    "                map_webid(i[\"WebId\"]),\n",
    "                i.get(\"TemplateName\", \"\"),\n",
    "                i.get(\"Description\", \"\"),\n",
    "            )\n",
    "            for i in js[\"Items\"]\n",
    "        }\n",
    "        if extract_key:\n",
    "            result = d.get(extract_key, None)\n",
    "            if result is None:\n",
    "                print(\n",
    "                    f\"[@error url={url}, key={key}, extract={extract_key}, d={d}]\"\n",
    "                )  # \" r={js}, d={d}\")\n",
    "            return result\n",
    "        else:\n",
    "            return d\n",
    "\n",
    "\n",
    "# Extract static value v2\n",
    "async def extract_static_value2(attr_info, client):\n",
    "    return await extract_point_or_value(\n",
    "        attr_info, client, \"Value\", \"Value\", lambda t: t\n",
    "    )\n",
    "\n",
    "\n",
    "# Extract point data v2\n",
    "async def extract_point2(attr_info, client):\n",
    "    # \"Path\", lambda t: extract_tag(t)\n",
    "    return await extract_point_or_value(\n",
    "        attr_info, client, \"Point\", \"Name\", lambda t: f\"tag__{t}\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Extract point or static value from attribute\n",
    "async def extract_point_or_value(attr_info, client, link_key, value_key, value_f):\n",
    "    if attr_info[\"Links\"].get(link_key, None) is None:\n",
    "        return None, None, None, None\n",
    "    start = process_time()\n",
    "    print(\".\", end=\"\")\n",
    "    r = await client.get(attr_info[\"Links\"][link_key], auth=auth, timeout=timeout)\n",
    "    # print(f\"[{process_time() - start:.2f}:{attr_info['Links'][link_key]}]\")\n",
    "    if r.status_code != 200:\n",
    "        print(f\"@get error code={r.status_code} url={attr_info['Links'][link_key]}\")\n",
    "        return\n",
    "    js = r.json()\n",
    "    point_attributes = None\n",
    "    if link_key == \"Point\":\n",
    "        r2 = await client.get(js[\"Links\"][\"Attributes\"], auth=auth, timeout=timeout)\n",
    "        if r2.status_code != 200:\n",
    "            print(f\"@get error code={r.status_code} url2={js['Links']['Attributes']}\")\n",
    "            return\n",
    "        point_attributes = r2.json()[\"Items\"]\n",
    "    return attr_info, value_f(js[value_key]), js, point_attributes\n",
    "\n",
    "\n",
    "def create_or_update_node(\n",
    "    node_type, name, webid, template=\"\", asset_db=\"\", parent=None\n",
    "):\n",
    "    ##query = f\"MATCH (node) WHERE node.id = '{webid}' RETURN node\"\n",
    "\n",
    "    nodes = []  ## [i[\"node\"] for i in graph.run(query).data()]\n",
    "    if len(nodes) == 1:\n",
    "        print(\"@\", end=\"\")\n",
    "        return nodes[0]\n",
    "    node = Node(node_type, name=name)  ### node_type, \"Node\"\n",
    "    node.update(id=webid, af_template=template, asset_db=asset_db)\n",
    "    # if node_type == \"PIPoint\":\n",
    "    #    node.update(on_ocs=1)\n",
    "    return node\n",
    "\n",
    "\n",
    "important_nodes = {}\n",
    "\n",
    "# Navigate fully AF `path` in PIWebAPI\n",
    "# If `graph` is not null, update it while traversing tree\n",
    "# (graph at this point is a list of Node and Relationship)\n",
    "async def elements_of(url, path, lgraph=None):\n",
    "    path_components = enumerate([i for i in path.split(\"\\\\\") if len(i) > 0])\n",
    "    # url = base_url\n",
    "    parent = None\n",
    "    asset_db = \"\"\n",
    "    for i, component in path_components:\n",
    "        # url, webid, template, description\n",
    "        result = await extract_url(\n",
    "            url, \"Databases\" if i == 0 else \"Elements\", component\n",
    "        )\n",
    "        if result is None:\n",
    "            print(f\"[@@@error: url={url}, i={i}, component={component}]\")\n",
    "            continue\n",
    "        url, webid, template, description = result\n",
    "        if lgraph is not None:\n",
    "            node_type = \"Server\" if i == 0 else (\"Database\" if i == 1 else \"Element\")\n",
    "            if node_type == \"Database\":\n",
    "                important_nodes[node_type] = webid\n",
    "\n",
    "            rel_type = (\n",
    "                \"NOT_POSSIBLE\"\n",
    "                if i == 0\n",
    "                else (\"HAS_DATABASE\" if i == 1 else \"HAS_ELEMENT\")\n",
    "            )\n",
    "            if node_type == \"Database\":\n",
    "                asset_db = ocs_asset_db  # component\n",
    "            node = create_or_update_node(\n",
    "                node_type, component, webid, template, asset_db\n",
    "            )\n",
    "            if node_type == \"Database\":\n",
    "                node.update(\n",
    "                    name=config[\"db\"][\"database_name\"],\n",
    "                    informationURL=config[\"db\"][\"infoURL\"],\n",
    "                    description=config[\"db\"][\"description\"],\n",
    "                    namespace=config[\"ocs\"][\"configuration\"][\"namespace\"],\n",
    "                    status=\"onboarding\",\n",
    "                )\n",
    "                important_nodes[node_type] = node\n",
    "            elif node_type == \"Element\":\n",
    "                node.update(description=description if description != \"\" else template)\n",
    "            if parent:\n",
    "                lgraph.append(Relationship(parent, rel_type, node))\n",
    "            lgraph.append(node)\n",
    "            parent = node\n",
    "\n",
    "    if important_nodes.get(\"Element\", None) is None:\n",
    "        important_nodes[\"Element\"] = node\n",
    "    print(f\"important nodes={important_nodes}\")\n",
    "    start = process_time()\n",
    "    urls_dict = await extract_url(url, \"Attributes\")\n",
    "    # print(f\"[{process_time() - start:.2f}:extract_url_{url}]\")\n",
    "    return urls_dict, parent\n",
    "\n",
    "\n",
    "# From an element URL, return a dictionary of attribute and their PIWebAPI JSON info\n",
    "# PIWebAPI attribute JSON to be parsed and transfered to graph\n",
    "async def attributes(url):\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        start = process_time()\n",
    "        print(\">\", end=\"\")\n",
    "        r = await client.get(url, auth=auth, timeout=timeout)\n",
    "        # print(f\"[{process_time() - start:.2f}:{url}]\")\n",
    "        if r.status_code != 200:\n",
    "            print(\"@error\")\n",
    "            return\n",
    "        js = r.json()\n",
    "        d = {\n",
    "            i[\"Name\"]: i for i in js[\"Items\"] if i[\"DataReferencePlugIn\"] == \"PI Point\"\n",
    "        }\n",
    "        for k in d.keys():  # key_list\n",
    "            # print(f\"d-key={k}\")\n",
    "            d[k] = await extract_point2(d[k], client)\n",
    "\n",
    "        d2 = {i[\"Name\"]: i for i in js[\"Items\"] if i[\"DataReferencePlugIn\"] == \"\"}\n",
    "        for k in d2.keys():\n",
    "            # print(f\"d2-key={k}\")\n",
    "            d2[k] = await extract_static_value2(d2[k], client)\n",
    "\n",
    "        return {**d, **d2}\n",
    "\n",
    "\n",
    "def convert_config_data(value):\n",
    "    if type(value) == float:\n",
    "        if str(value)[-2:] == \".0\":\n",
    "            return int(value)\n",
    "        else:\n",
    "            return value\n",
    "    try:\n",
    "        return int(value)\n",
    "    except (ValueError, TypeError):\n",
    "        try:\n",
    "            val = value[\"Name\"]\n",
    "            return val.replace(\"'\", \"\")  # f\"'{val}'\"\n",
    "        except:\n",
    "            return value.replace(\"'\", \"\")  # \"'{value}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform linear graph (list of Node and Relationship) into list of GraphQL mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GraphQL client object\n",
    "sample_transport = RequestsHTTPTransport(\n",
    "    url=config[\"graphql\"][\"endpoint\"], verify=False, retries=3\n",
    ")\n",
    "client = Client(transport=sample_transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commit_graph(g, debug=True):\n",
    "    start_time = time.perf_counter()\n",
    "    # tx = graph.begin()\n",
    "    if debug:\n",
    "        print(f\"\\n>> Graph root={g[0]}\")\n",
    "    # [tx.create(i) for i in g if i is not None]\n",
    "    for node in g:\n",
    "        if node is None:\n",
    "            print(\"### [None]\")\n",
    "        else:\n",
    "            if type(node) == py2neo.data.Node:\n",
    "                ntype = str(node.labels).replace(\":\", \"\").replace(\"Node\", \"\")\n",
    "                d = dict(node)\n",
    "                d.pop(\"step\", None)  ## temporary\n",
    "                d.pop(\"on_ocs\", None)  ## temporary\n",
    "                args = \",\".join([f' {key}: \"{d[key]}\"' for key in d.keys()])\n",
    "                print(\"@@@@@\", ntype, d)\n",
    "                node_mutation = gql(\n",
    "                    f\"\"\"\n",
    "                mutation \n",
    "                   {{ Merge{ntype}({args}) {{\n",
    "                       id \n",
    "                       name\n",
    "                   }}\n",
    "                   }}\n",
    "                \"\"\"\n",
    "                )\n",
    "                client.execute(node_mutation)\n",
    "    for relation in g:\n",
    "        if relation is None:\n",
    "            print(\"### [None]\")\n",
    "        else:\n",
    "            if type(relation) != py2neo.data.Node:  # must a relationship\n",
    "                start_node = relation.start_node\n",
    "                end_node = relation.end_node\n",
    "                ntype = str(start_node.labels).replace(\":\", \"\").replace(\"Node\", \"\")\n",
    "                merge_suffix = type(relation).__name__.capitalize()\n",
    "                args = f\"\"\"from: {{id: \\\"{start_node['id']}\\\"}}, to: {{id: \\\"{end_node['id']}\\\"}}\"\"\"\n",
    "                mutation = f\"\"\" \n",
    "                mutation {{ \n",
    "                    Merge{ntype}{merge_suffix}({args}) {{\n",
    "                        from {{\n",
    "                            name\n",
    "                        }}\n",
    "                        to {{\n",
    "                            name\n",
    "                        }}\n",
    "                    }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "                relation_mutation = gql(mutation)\n",
    "                ## print(\">>>>> mutation=\", mutation)\n",
    "                reply = client.execute(relation_mutation)\n",
    "                print(\"<<<<<<\", reply)\n",
    "    # tx.commit()\n",
    "    if debug:\n",
    "        print(f\">> commit done in {time.perf_counter() - start_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all children element nodes of anchor element and their attributes\n",
    "\n",
    "For attributes, transfer relevent information onto associated graph node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reject_element(element_name):\n",
    "    return any(ss in element_name.lower() for ss in [\"_cache\", \"baseline\", \"health\"])\n",
    "\n",
    "try:\n",
    "    exec(config[\"reject_element\"])\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_leaf_element_attributes(elements_path):\n",
    "    lgraph = []\n",
    "    elem_attr_urls, elem_anchor = await elements_of(\n",
    "        asset_url, elements_path, lgraph=lgraph\n",
    "    )\n",
    "    print(f\"\\n>> Current anchor: {elem_anchor}\")\n",
    "    # elem_anchor, len(lgraph if lgraph else []), list(elem_attr_urls.keys())\n",
    "    for element_name in elem_attr_urls.keys():\n",
    "        # UC Davis + CMU specific\n",
    "        if reject_element(element_name):\n",
    "            print(f\"@@ rejected: {element_name}\")\n",
    "            continue\n",
    "        name = element_name\n",
    "        # print(elem_attr_urls[element_name])\n",
    "        elem_url, webid, template, description = elem_attr_urls[element_name]\n",
    "        elem_node = create_or_update_node(\n",
    "            \"Element\", name, webid, template, asset_db=elem_anchor[\"asset_db\"]\n",
    "        )\n",
    "        elem_node.update(description=description if description != \"\" else template)\n",
    "        elem_rel = Relationship(elem_anchor, \"HAS_ELEMENT\", elem_node)\n",
    "        attributes_info = await attributes(elem_attr_urls[element_name][0])\n",
    "        static_attributes = []\n",
    "        for attr in attributes_info.keys():\n",
    "            try:\n",
    "                attr_info, stream_or_val, stream_js, point_attrs = attributes_info[attr]\n",
    "            except ValueError:\n",
    "                print(f\"attr={attr}  val={attributes_info[attr]}\")\n",
    "                return\n",
    "            if attr_info is None:\n",
    "                continue\n",
    "            if \"tag__\" not in str(stream_or_val):\n",
    "                node = create_or_update_node(\n",
    "                    \"Attribute\",\n",
    "                    attr,\n",
    "                    map_webid(attr_info[\"WebId\"]),\n",
    "                    template=elem_node[\"af_template\"],\n",
    "                    asset_db=elem_node[\"asset_db\"],\n",
    "                )\n",
    "                node.update(\n",
    "                    value=convert_config_data(stream_or_val), type=attr_info[\"Type\"]\n",
    "                )\n",
    "                rel = Relationship(elem_node, \"HAS_ATTRIBUTE\", node)\n",
    "                lgraph.extend([node, rel])\n",
    "                static_attributes += [attr]\n",
    "                continue\n",
    "\n",
    "            stream_name = stream_or_val.replace(\"tag__\", \"\")\n",
    "            if \"Analysis\" in attr:  # NOTE: duplicate tag in attributes for FV\n",
    "                # skip attribute with duplicate tag\n",
    "                print(\"=\", end=\"\")\n",
    "                continue\n",
    "            if stream_js[\"Future\"]:\n",
    "                # future tag not transferred by PItoOCS\n",
    "                print(f\"${attr}$\", end=\"\")\n",
    "                continue\n",
    "            node = create_or_update_node(\n",
    "                \"PIPoint\",\n",
    "                attr,\n",
    "                map_webid(attr_info[\"WebId\"]),\n",
    "                elem_node[\"af_template\"],\n",
    "                elem_node[\"asset_db\"],\n",
    "            )\n",
    "            print(\"+\", end=\"\")  # stream_name\n",
    "            pattributes = {i[\"Name\"]: i[\"Value\"] for i in point_attrs}\n",
    "            node.update(\n",
    "                asset_id=name,\n",
    "                column_name=attr,\n",
    "                stream_name=stream_name,\n",
    "                type=attr_info[\"Type\"],\n",
    "                uom=attr_info[\"DefaultUnitsName\"],\n",
    "                step=attr_info[\"Step\"],\n",
    "                categories=attr_info[\"CategoryNames\"],\n",
    "                description=attr_info[\"Description\"],\n",
    "                pointsource=pattributes[\"pointsource\"],\n",
    "                stream_id=f\"PI_{config['piwebapi']['dataserver']}_{pattributes['pointid']}\",\n",
    "            )\n",
    "            if (\n",
    "                attr_info[\"Type\"] == \"EnumerationValue\"\n",
    "                or stream_js[\"PointType\"] == \"Digital\"\n",
    "            ):\n",
    "                # print(f\"node={node}, js={stream_js}\")\n",
    "                node.update(digital_set_name=stream_js[\"DigitalSetName\"])\n",
    "            rel = Relationship(elem_node, \"HAS_DYNAMIC\", node)\n",
    "            lgraph.extend([node, rel])\n",
    "        elem_node.update(static_attributes=static_attributes)\n",
    "        lgraph.extend([elem_node, elem_rel])\n",
    "    commit_graph(lgraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate and commit graphs (one per anchor elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def build_graphs(roots):\n",
    "    for elements_path in roots:\n",
    "        # lgraph = []\n",
    "        await generate_leaf_element_attributes(elements_path)  # , lgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(element_roots)\n",
    "start_time = time.perf_counter()\n",
    "await build_graphs(element_roots)\n",
    "print(f\"> runtime {time.perf_counter() - start_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_node = important_nodes[\"Database\"]\n",
    "elem_root = important_nodes[\"Element\"]\n",
    "root_webid = elem_root[\"id\"]\n",
    "print(elem_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) From a test element, produce the list of all attributes\n",
    "\n",
    "Data Views are created from different subset of this list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "\n",
    "async def gather_func(f, items, ndiv):\n",
    "    div = (len(items) // ndiv) + 1\n",
    "    chunk_list = list(chunks(items, div))\n",
    "    coroutines = [f(chunk_list[i]) for i in range(0, ndiv)]\n",
    "    start_time = time.perf_counter()\n",
    "    print(\"-OK-\") if await asyncio.gather(*coroutines) else print(\"@oops\")\n",
    "    print(f\"> runtime {time.perf_counter() - start_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define reject_element function if needed in config yaml\n",
    "try:\n",
    "    exec(config[\"reject_leaf_element\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "query_leaves = gql(\n",
    "    \"\"\"\n",
    "query Database($asset_db: String) {\n",
    "    Database(asset_db: $asset_db) {\n",
    "        leaf_elements {\n",
    "            name\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "if EXPAND_LEAF_ELEMENTS:\n",
    "    ndiv = 3\n",
    "    root = element_roots[0]\n",
    "    # query = f\"MATCH (e:Element) WHERE NOT ((e)-[:HAS_ELEMENT]->()) and e.asset_db='{ocs_asset_db}' RETURN DISTINCT e.name AS name ORDER BY e.name\"\n",
    "    # leaf_elements = [i[\"name\"] for i in graph.run(query).data()]\n",
    "    result = client.execute(query_leaves, variable_values={\"asset_db\": ocs_asset_db})\n",
    "    print(result)\n",
    "    leaf_elements = [i[\"name\"] for i in result[\"Database\"][0][\"leaf_elements\"]]\n",
    "    roots = [root + f\"\\\\{element}\" for element in leaf_elements[:MAX_LEAF_ELEMENTS]]\n",
    "    print(len(roots), roots)\n",
    "    # await gather_func(build_graphs, roots, ndiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataserver_urls = (requests.get(base_url + \"/dataservers\", auth=auth).json())[\"Items\"]\n",
    "for ds in dataserver_urls:\n",
    "    if dataserver == ds[\"Name\"]:\n",
    "        print(ds)\n",
    "        enums_url = ds[\"Links\"][\"EnumerationSets\"]\n",
    "        break\n",
    "print(enums_url)\n",
    "enums = requests.get(enums_url, auth=auth)\n",
    "enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all Digital Sets referred to by dataset PIPoint\n",
    "query_pipoint = gql(\n",
    "    \"\"\"\n",
    "query PIPoint($asset_db: String!) { \n",
    "    PIPoint(asset_db: $asset_db) {\n",
    "        digital_set_name\n",
    "        id\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "result = client.execute(\n",
    "    query_pipoint, variable_values={\"asset_db\": ocs_asset_db}\n",
    ")  # ocs_asset_db})\n",
    "print(result)\n",
    "\n",
    "digital_sets = [\n",
    "    i[\"digital_set_name\"]\n",
    "    for i in result[\"PIPoint\"]\n",
    "    if i[\"digital_set_name\"] is not None\n",
    "]\n",
    "# print(set(digital_sets))\n",
    "\n",
    "dataset_enums = list(set(digital_sets))\n",
    "dataset_enums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DigitalState node with all states, add relationship :STATE_FROM from node with values in that DigitalState set\n",
    "for digital_set in dataset_enums:\n",
    "    # print(\"digital_set:\", digital_set)\n",
    "    d = {}\n",
    "    for i in (enums.json())[\"Items\"]:\n",
    "        if i[\"Name\"] == digital_set:\n",
    "            print(f\"==> processing {i}...\")\n",
    "            vals = requests.get(i[\"Links\"][\"Values\"], auth=auth).json()\n",
    "            for v in vals[\"Items\"]:\n",
    "                if v[\"Name\"] != \"undefined\":\n",
    "                    # print(f\"{v['Value']} - {v['Name']}\")\n",
    "                    d[str(v[\"Value\"])] = v[\"Name\"]\n",
    "            node = create_or_update_node(\n",
    "                \"DigitalState\",\n",
    "                digital_set,\n",
    "                map_webid(i[\"WebId\"]),\n",
    "                asset_db=ocs_asset_db,\n",
    "            )\n",
    "            node.update(states=str(d))\n",
    "            lgraph = [node]\n",
    "            commit_graph(lgraph)\n",
    "            digital_query = gql(\n",
    "                \"\"\"\n",
    "                query PIPoint($asset_db: String, $digital_set: String) {\n",
    "                    PIPoint(asset_db: $asset_db, digital_set_name: $digital_set) {\n",
    "                        id\n",
    "                    }\n",
    "                }\n",
    "            \"\"\"\n",
    "            )\n",
    "            result = client.execute(\n",
    "                digital_query,\n",
    "                variable_values={\n",
    "                    \"asset_db\": ocs_asset_db,\n",
    "                    \"digital_set\": digital_set,\n",
    "                },  # ocs_asset_db\n",
    "            )\n",
    "            print(result)\n",
    "            digital_mutation = gql(\n",
    "                \"\"\"\n",
    "               mutation Digital($from: _PIPointInput!, $to: _DigitalStateInput!) {\n",
    "                   MergePIPointState_from(from: $from, to: $to) {\n",
    "                       from {\n",
    "                           name\n",
    "                       }\n",
    "                       to {\n",
    "                           name\n",
    "                       }\n",
    "                   }\n",
    "               }\n",
    "               \n",
    "            \"\"\"\n",
    "            )\n",
    "            for p in result[\"PIPoint\"]:\n",
    "                result = client.execute(\n",
    "                    digital_mutation,\n",
    "                    variable_values={\"from\": {\"id\": p[\"id\"]}, \"to\": {\"id\": node[\"id\"]}},\n",
    "                )\n",
    "                print(\">>>>\", result)\n",
    "            \"\"\"\n",
    "            points = [\n",
    "                i[\"p\"]\n",
    "                for i in graph.run(\n",
    "                    f\"MATCH (p:PIPoint) WHERE p.digital_set_name = '{digital_set}' RETURN p\"\n",
    "                ).data()\n",
    "            ]\n",
    "            for p in points:\n",
    "                rel = Relationship(p, \"STATE_FROM\", node)\n",
    "                lgraph.extend([rel])\n",
    "\n",
    "            break\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

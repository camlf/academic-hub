{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: build OCS data views, map metadata to streams \n",
    "\n",
    "#### This notebook synchronize OCS with the graph, meaning tags and metadata are added to target OCS streams and associated Data Views are created \n",
    "\n",
    "#### All Data Views share the same structure. The information needed to create one are:\n",
    "\n",
    "* Database name (asset_db)\n",
    "* List of Asset ID \n",
    "* OCS tag \n",
    "\n",
    "Data View sample below with: \n",
    "\n",
    "* `asset_db:brewey`\n",
    "* `asset_id:FV31`\n",
    "* `hub__all_columns` as tag "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "  \"Id\": \"test-dv\",\n",
    "  \"Name\": \"test-dv\",\n",
    "  \"Description\": \"Test Description\",\n",
    "  \"IndexField\": {\n",
    "    \"Source\": \"NotApplicable\",\n",
    "    \"Keys\": [],\n",
    "    \"Label\": \"Timestamp\"\n",
    "  },\n",
    "  \"Queries\": [\n",
    "    {\n",
    "      \"Id\": \"Asset_value\",\n",
    "      \"Kind\": \"Stream\",\n",
    "      \"Value\": \"asset_db:brewery AND asset_id:FV31 AND hub__all_columns\"\n",
    "    },\n",
    "    {\n",
    "      \"Id\": \"Asset_digital\",\n",
    "      \"Kind\": \"Stream\",\n",
    "      \"Value\": \"asset_db:brewery AND asset_id:FV31 AND hub__all_columns AND TypeId:PI-Digital\"\n",
    "    }\n",
    "  ],\n",
    "  \"DataFieldSets\": [\n",
    "    {\n",
    "      \"QueryId\": \"Asset_value\",\n",
    "      \"DataFields\": [\n",
    "        {\n",
    "          \"Source\": \"PropertyId\",\n",
    "          \"Keys\": [\n",
    "            \"Value\"\n",
    "          ],\n",
    "          \"Label\": \"{IdentifyingValue}\"\n",
    "        }\n",
    "      ],\n",
    "      \"IdentifyingField\": {\n",
    "        \"Source\": \"Metadata\",\n",
    "        \"Keys\": [\n",
    "          \"column_name\"\n",
    "        ],\n",
    "        \"Label\": \"{IdentifyingValue} {FirstKey}\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"QueryId\": \"Asset_digital\",\n",
    "      \"DataFields\": [\n",
    "        {\n",
    "          \"Source\": \"PropertyId\",\n",
    "          \"Keys\": [\n",
    "            \"DigitalStateName\"\n",
    "          ],\n",
    "          \"Label\": \"{IdentifyingValue}__ds\"\n",
    "        }\n",
    "      ],\n",
    "      \"IdentifyingField\": {\n",
    "        \"Source\": \"Metadata\",\n",
    "        \"Keys\": [\n",
    "          \"column_name\"\n",
    "        ],\n",
    "        \"Label\": \"{IdentifyingValue} {FirstKey}\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"GroupingFields\": [\n",
    "    {\n",
    "      \"Source\": \"Metadata\",\n",
    "      \"Keys\": [\n",
    "        \"Asset_Id\"\n",
    "      ],\n",
    "      \"Label\": \"{IdentifyingValue} {FirstKey}\"\n",
    "    }\n",
    "  ],\n",
    "  \"DefaultStartIndex\": \"2017-02-07T00:00\",\n",
    "  \"DefaultEndIndex\": \"2017-02-27T00:00\",\n",
    "  \"DefaultInterval\": \"00:05:00\",\n",
    "  \"IndexTypeCode\": \"DateTime\",\n",
    "  \"Shape\": \"Standard\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from gql import gql, Client\n",
    "from gql.transport.requests import RequestsHTTPTransport\n",
    "import httpx\n",
    "import json\n",
    "import time\n",
    "import urllib3\n",
    "from ocs_academic_hub import HubClient\n",
    "import yaml\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# config_file = \"config-windfarm.yaml\"  # \"config-acad-prod-desc-v2.yaml\"\n",
    "config_file = \"config-prod-ucd-v2.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OCS_HUB_CONFIG=config-dv.ini\n",
    "hub = HubClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace_id = config[\"ocs\"][\"configuration\"][\"namespace\"]  # \"academic_hub_01\"\n",
    "asset_db = config[\"ocs\"][\"configuration\"][\"asset_db\"]  # \"deschutes\"\n",
    "\n",
    "tag_prefix = \"hub__\"\n",
    "timeout = 45.0\n",
    "\n",
    "streams = hub.Streams.getStreams(namespace_id, query=\"name:*\", count=20000)\n",
    "len(streams), streams[0].Id, streams[0].Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = {s.Name: s.Id for s in streams}\n",
    "len(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def request(method, url, params=None, data=None, headers=None, **kwargs):\n",
    "    if not headers:\n",
    "        headers = hub._OCSClient__baseClient.sdsHeaders()\n",
    "\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        r = await client.request(\n",
    "            method,\n",
    "            url,\n",
    "            params=params,\n",
    "            data=data,\n",
    "            headers=headers,\n",
    "            timeout=timeout,\n",
    "            **kwargs\n",
    "        )\n",
    "    return r\n",
    "\n",
    "\n",
    "async def update_tags(namespace_id, stream_name, new_tags, hub_clean=False):\n",
    "    if namespace_id is None:\n",
    "        raise TypeError\n",
    "\n",
    "    try:\n",
    "        streamId = name2id[stream_name]\n",
    "    except KeyError:\n",
    "        return\n",
    "    response = await request(\n",
    "        \"get\",\n",
    "        hub._OCSClient__Streams._Streams__streamsPath.format(\n",
    "            tenant_id=hub.tenant, namespace_id=namespace_id, stream_id=streamId\n",
    "        )\n",
    "        + \"/Tags\",\n",
    "    )\n",
    "\n",
    "    current_tags = json.loads(response.text)\n",
    "    if hub_clean:\n",
    "        tags = [tag for tag in current_tags if \"hub__\" not in tag]\n",
    "    else:\n",
    "        tags = list(set(current_tags + [tag_prefix + i for i in new_tags]))\n",
    "\n",
    "    response = await request(\n",
    "        \"put\",\n",
    "        hub._OCSClient__Streams._Streams__streamsPath.format(\n",
    "            tenant_id=hub.tenant, namespace_id=namespace_id, stream_id=streamId\n",
    "        )\n",
    "        + \"/Tags\",\n",
    "        data=json.dumps(tags),\n",
    "    )\n",
    "    # print(f\"[{stream_name}]-tags={tags}\")\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_metadata(namespace_id, stream_name, new_meta):\n",
    "    if namespace_id is None:\n",
    "        raise TypeError\n",
    "\n",
    "    try:\n",
    "        streamId = name2id[stream_name]\n",
    "    except KeyError:\n",
    "        return None\n",
    "    response = await request(\n",
    "        \"get\",\n",
    "        hub._OCSClient__Streams._Streams__streamsPath.format(\n",
    "            tenant_id=hub.tenant, namespace_id=namespace_id, stream_id=streamId\n",
    "        )\n",
    "        + \"/Metadata\",\n",
    "    )\n",
    "\n",
    "    metadata = json.loads(response.text)\n",
    "    metadata.update(new_meta)\n",
    "    response = await request(\n",
    "        \"put\",\n",
    "        hub._OCSClient__Streams._Streams__streamsPath.format(\n",
    "            tenant_id=hub.tenant, namespace_id=namespace_id, stream_id=streamId\n",
    "        )\n",
    "        + \"/Metadata\",\n",
    "        data=json.dumps(metadata),\n",
    "    )\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_stream(stream_info):\n",
    "    m = await update_metadata(\n",
    "        namespace_id,\n",
    "        stream_info[\"stream_name\"],\n",
    "        {\n",
    "            \"asset_db\": stream_info[\"asset_db\"],\n",
    "            \"asset_id\": stream_info[\"asset_id\"],\n",
    "            \"column_name\": stream_info[\"name\"],\n",
    "        },\n",
    "    )\n",
    "    dv = stream_info[\"dataviews\"]\n",
    "    new_tags = [i[\"ocs_tag\"] for i in dv]\n",
    "    t = await update_tags(namespace_id, stream_info[\"stream_name\"], new_tags)\n",
    "    if m and t:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def update_streams(streams_info):\n",
    "    for stream_info in streams_info:\n",
    "        # print(f\"-[{stream_info['stream_name']}]- \", end=\"\")\n",
    "        print(f\"+\", end=\"\")\n",
    "        r = await update_stream(stream_info)\n",
    "        if not r:\n",
    "            print(f\"@error({stream_info['stream_name']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transport = RequestsHTTPTransport(\n",
    "    url=config[\"graphql\"][\"endpoint\"], verify=False, retries=3\n",
    ")\n",
    "client = Client(transport=sample_transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_query = gql(\n",
    "    \"\"\"\n",
    "query PIPoint_tags($asset_db: String) {\n",
    "  PIPoint(asset_db: $asset_db) {\n",
    "    asset_db\n",
    "    asset_id\n",
    "    name\n",
    "    stream_name\n",
    "    dataviews {\n",
    "      name\n",
    "      ocs_tag\n",
    "      asset_id\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "streams = client.execute(streams_query, variable_values={\"asset_db\": config[\"ocs\"][\"configuration\"][\"asset_db\"]})\n",
    "print(streams[\"PIPoint\"][0])\n",
    "# print(json.dumps(dataviews, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await update_stream(streams[\"PIPoint\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i : i + n]\n",
    "\n",
    "\n",
    "async def gather_func(f, items, ndiv):\n",
    "    div = (len(items) // ndiv) + 1\n",
    "    chunk_list = list(chunks(items, div))\n",
    "    coroutines = [f(chunk_list[i]) for i in range(0, ndiv)]\n",
    "    start_time = time.perf_counter()\n",
    "    print(\"-OK-\") if await asyncio.gather(*coroutines) else print(\"@oops\")\n",
    "    print(f\"> runtime {time.perf_counter() - start_time:.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if config[\"ocs\"][\"configuration\"].get(\"update_streams\", True):\n",
    "    await gather_func(update_streams, streams[\"PIPoint\"], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataview_query = gql(\n",
    "    \"\"\"\n",
    "query DataViews($asset_db: String) {\n",
    "  DataView(ocs_sync: false, asset_db: $asset_db, orderBy: id_asc) {\n",
    "    name\n",
    "    id\n",
    "    asset_db\n",
    "    asset_id\n",
    "    ocs_tag\n",
    "    description\n",
    "    has_stream {\n",
    "      name\n",
    "      stream_name\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "dataviews = client.execute(\n",
    "    dataview_query,\n",
    "    variable_values={\"asset_db\": config[\"ocs\"][\"configuration\"][\"asset_db\"]},\n",
    ")\n",
    "# print(dataviews[\"DataView\"][0])\n",
    "print(json.dumps(dataviews, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dv_header(asset_id, dv_name, dv_id, description):\n",
    "    return {\n",
    "        \"Id\": dv_id,\n",
    "        \"Name\": dv_id,\n",
    "        \"Description\": description,\n",
    "        \"IndexField\": {\"Source\": \"NotApplicable\", \"Keys\": [], \"Label\": \"Timestamp\"},\n",
    "    }\n",
    "\n",
    "\n",
    "def dv_query(asset_db, asset_id, tag, asset_type, value_addition=\"\"):\n",
    "    if len(asset_id) == 1:\n",
    "        asset_clause = f'asset_id:\"{asset_id[0]}\"'\n",
    "    else:\n",
    "        asset_clause = (\n",
    "            \"(\" + \" OR \".join([f'asset_id:\"{asset}\"' for asset in asset_id]) + \")\"\n",
    "        )\n",
    "    return {\n",
    "        \"Id\": f\"Asset_{asset_type}\",\n",
    "        \"Kind\": \"Stream\",\n",
    "        \"Value\": f'asset_db:\"{asset_db}\" AND {asset_clause} AND {tag}{value_addition}',\n",
    "    }\n",
    "\n",
    "\n",
    "def dv_datafield(asset_type, key, label_suffix=\"\"):\n",
    "    return {\n",
    "        \"QueryId\": f\"Asset_{asset_type}\",\n",
    "        \"DataFields\": [\n",
    "            {\n",
    "                \"Source\": \"PropertyId\",\n",
    "                \"Keys\": [key],\n",
    "                \"Label\": f\"{{IdentifyingValue}}{label_suffix}\",\n",
    "            }\n",
    "        ],\n",
    "        \"IdentifyingField\": {\n",
    "            \"Source\": \"Metadata\",\n",
    "            \"Keys\": [\"column_name\"],\n",
    "            \"Label\": \"{IdentifyingValue} {FirstKey}\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "def dv_footer():\n",
    "    return {\n",
    "        \"GroupingFields\": [\n",
    "            {\n",
    "                \"Source\": \"Metadata\",\n",
    "                \"Keys\": [\"Asset_Id\"],\n",
    "                \"Label\": \"{IdentifyingValue} {FirstKey}\",\n",
    "            }\n",
    "        ],\n",
    "        \"DefaultStartIndex\": \"2017-02-07T00:00\",\n",
    "        \"DefaultEndIndex\": \"2017-02-27T00:00\",\n",
    "        \"DefaultInterval\": \"00:05:00\",\n",
    "        \"IndexTypeCode\": \"DateTime\",\n",
    "        \"Shape\": \"Standard\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dv(asset_id, tag, dv_id, dv_name, description):\n",
    "    tag = \"hub__\" + tag\n",
    "    dvh = dv_header(asset_id, dv_name, dv_id, description)\n",
    "    dvq = {\n",
    "        \"Queries\": [\n",
    "            dv_query(asset_db, asset_id, tag, \"value\"),\n",
    "            dv_query(asset_db, asset_id, tag, \"digital\", \" AND TypeId:PI-Digital\"),\n",
    "        ]\n",
    "    }\n",
    "    dvdf = {\n",
    "        \"DataFieldSets\": [\n",
    "            dv_datafield(\"value\", \"Value\"),\n",
    "            dv_datafield(\"digital\", \"DigitalStateName\", \"__ds\"),\n",
    "        ]\n",
    "    }\n",
    "    dvf = dv_footer()\n",
    "\n",
    "    dv = {**dvh, **dvq, **dvdf, **dvf}\n",
    "\n",
    "    return dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = build_dv([\"FV31\"], \"all_columns\", \"test-dv\", \"Default\", \"Test Description\")\n",
    "print(json.dumps(dv, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from ocs_sample_library_preview import DataView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataview_mutation = gql(\n",
    "    \"\"\"\n",
    "mutation SyncDV($id: ID!) {\n",
    "  MergeDataView(id: $id, ocs_sync: true) {\n",
    "    id\n",
    "    ocs_sync\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def sync_dataview(dv_def):\n",
    "    dv = build_dv(\n",
    "        dv_def[\"asset_id\"],\n",
    "        dv_def[\"ocs_tag\"],\n",
    "        dv_def[\"id\"],\n",
    "        dv_def[\"name\"],\n",
    "        dv_def[\"description\"],\n",
    "    )\n",
    "    # print(json.dumps(dv, indent=2))\n",
    "    dataview = DataView.fromDictionary(dv)\n",
    "    hub.DataViews.putDataView(namespace_id, dataview)\n",
    "    result = client.execute(dataview_mutation, variable_values={\"id\": dv_def[\"id\"]})\n",
    "    print(f\"[{result}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dv_def in dataviews[\"DataView\"]:\n",
    "    sync_dataview(dv_def)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sample_transport = RequestsHTTPTransport(\n",
    "    url=\"https://data.academic.osisoft.com/tubgraphql\", verify=False, retries=3\n",
    ")\n",
    "client = Client(transport=sample_transport, fetch_schema_from_transport=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "wid = gql(\n",
    "    \"\"\"\n",
    "{ Database(name: \"Campus_Facility\") {\n",
    "   asset_with_dv(orderBy: name_asc) {\n",
    "       name\n",
    "       id\n",
    "   }\n",
    "}}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "r = client.execute(wid)\n",
    "r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "meta_query = gql(\n",
    "    \"\"\"\n",
    "{\n",
    "  Database(name: \"Campus_Energy\") {\n",
    "    asset_with_dv(orderBy: name_asc) {\n",
    "      name\n",
    "      id\n",
    "      has_attribute(filter: { hub_meta: true }, orderBy: name_asc) {\n",
    "        name\n",
    "        value\n",
    "      }\n",
    "      has_element(\n",
    "        orderBy: name_asc\n",
    "        filter: {\n",
    "          OR: [\n",
    "            { name: \"Electricity\" }\n",
    "            { name: \"ChilledWater\" }\n",
    "            { name: \"Steam\" }\n",
    "          ]\n",
    "        }\n",
    "      ) {\n",
    "        name\n",
    "        has_attribute(filter: { hub_meta: true }, orderBy: name_asc) {\n",
    "          name\n",
    "          value\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "result = client.execute(meta_query)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "result[\"Database\"][0][\"asset_with_dv\"][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def convert2value(s):\n",
    "    if \".\" in s:\n",
    "        try:\n",
    "            return(float(s))\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        return(int(s))\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "convert2value(\"    1.\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def extract_meta(js, sub=False):\n",
    "    j = js[\"has_attribute\"]\n",
    "    prefix = \"\" if not sub else (js[\"name\"].lower() + \".\")\n",
    "    return {f\"{prefix}{k['name']}\": convert2value(k[\"value\"]) for k in j}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d = extract_meta(result[\"Database\"][0][\"asset_with_dv\"][0])\n",
    "d"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "d.update(extract_meta(result[\"Database\"][0][\"asset_with_dv\"][0]['has_element'][0], True))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(result[\"Database\"][0][\"asset_with_dv\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "meta_mutation = gql(\n",
    "    \"\"\"\n",
    "mutation UpdateMeta(\n",
    "  $id: ID!\n",
    "  $meta: String\n",
    "  $af: String!\n",
    "  $adb: String!\n",
    "  $name: String!\n",
    ") {\n",
    "  MergeElement(\n",
    "    id: $id\n",
    "    af_template: $af\n",
    "    asset_db: $adb\n",
    "    name: $name\n",
    "    hub_metadata: $meta\n",
    "  ) {\n",
    "    id\n",
    "    name\n",
    "    hub_metadata\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "element_query = gql(\n",
    "    \"\"\"\n",
    "query ElementById($id: ID!) { \n",
    "  Element(id: $id) {\n",
    "    id\n",
    "    af_template\n",
    "    asset_db\n",
    "    name\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def update_meta(wid, meta, elem):\n",
    "    result = client.execute(\n",
    "        meta_mutation,\n",
    "        variable_values={\n",
    "            \"id\": wid,\n",
    "            \"meta\": str(meta),\n",
    "            \"af\": elem[\"af_template\"],\n",
    "            \"adb\": elem[\"asset_db\"],\n",
    "            \"name\": elem[\"name\"],\n",
    "        },\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "def element_by_id(wid):\n",
    "    result = client.execute(element_query, variable_values={\"id\": wid})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "r = element_by_id(\"F1EmzO41BZK4DE21ZU4Yk9YqRQHcG0pq6i5xGpRwANOjB-OwVU5JLVBJQUYtVk0wXFVDIERBVklTXFVDIERBVklTXEJVSUxESU5HU1xBUkMgUEFWSUxJT04\")\n",
    "r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nb = len(result[\"Database\"][0][\"asset_with_dv\"])\n",
    "for i in range(nb):\n",
    "    dai = result[\"Database\"][0][\"asset_with_dv\"][i]\n",
    "    d = extract_meta(dai)\n",
    "    for j in range(len(dai[\"has_element\"])):\n",
    "        d.update(extract_meta(dai[\"has_element\"][j], True))\n",
    "    r = element_by_id(dai[\"id\"])\n",
    "    update_meta(dai[\"id\"], d, r[\"Element\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
